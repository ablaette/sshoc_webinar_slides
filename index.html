<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Quanlify with ease: Combining quantitative and qualitative corpus analysis</title>
    <meta charset="utf-8" />
    <meta name="author" content="Andreas Blaette" />
    <link href="index_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="index_files/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="index_files/remark-css-0.0.1/robot-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/polminify.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Quanlify with ease: Combining quantitative and qualitative corpus analysis
### Andreas Blaette
### April 13, 2020 (SSHOC webinar #2)

---




# Corpora everywhere. 

## But where do we stand?

--

There is no lack ...

- of algorithms
- of ideas and projects on research data management (implementing FAIR data principles)

But ...

--

* Acquisition of NLP techniques in the social sciences &amp; humanities still piecemeal

--

* Tools for processing text that scale well are lacking

--

* Availability of data for replication is missing 

--

* Reproducibility of data (getting FAIRER) is wanting

--

* __Integration of quantitative and qualitative approaches to text is an unfulfilled promise__

---
background-image: url(img/Bergbau_Sabine_Wahlen.jpg)
background-size: cover
class: nobackground, inverse

# PolMine Project
## Data and Code for Corpus Analysis

---

# www.polmine.de

## The PolMine Project

--

- __Research__&lt;/br&gt;
  On migration &amp; integration policy: MigTex, MIDEM, PopParl

--
- __Data__&lt;/br&gt;
  Corpora of plenary protocols, Newspaper articles, ...

--
- __Code__&lt;/br&gt;
  open source R packages for text analysis, at CRAN &amp; GitHub

--
- __Tutorials__&lt;/br&gt;
  Using Corpora in Social Science Research / UCSSR

--
- __Centre__&lt;/br&gt;
  CLARIN Centre category C, prospectively part of NFDI

&lt;br/&gt;
--
_Learn more: www.polmine.de_

---

# The hacky days shall be over

## Wrapping consolidated code into R packages

--

### Core packages published at CRAN

- *polmineR*: Wlementary vocabulary for corpus analysis ![](https://www.r-pkg.org/badges/version/polmineR)
- *RcppCWB*: R Wrapper for the C Code of the Corpus Workbench (using C++/Rcpp) ![](https://www.r-pkg.org/badges/version/RcppCWB)
- *cwbtools*: Tools to create and manage CWB indexed corpora ![](https://www.r-pkg.org/badges/version/cwbtools)

--

### A toolchain for corpus preparation

- *frapp*: Framework for Parsing Plenary Protocols
- *bignlp*: Fast NLP processing for big corpora (interfacing to Stanford CoreNLP)
- *biglda*: Fast LDA topic modelling (interfacing to MALLET)
- *ctk*: Corpus toolkit (misc functionality for corpus preparation)

--

Ensuring quality: Continuous integration (CI), moving to test-driven development, improving code coverage 

???

### Why R?

- the most common programming language in the social sciences
- comprehensive availability of statistical methods
- great visualisation capabilities
- usability: RStudio as IDE
- reproducible research: R Markdown notebooks

### Why the Corpus Workbench (CWB)?

- a classic toolset for corpus analysis
- indexing and compression of corpora =&gt; performance
- powerful and versatile syntax of the Corpus Query Processor (CQP)
- permissive license (GPL)



---

# Towards a data-rich future

### Corpora of Plenary Protocols

- **GermaParl**: Corpus of the German Bundestag, regional parliaments ![](https://zenodo.org/badge/DOI/10.5281/zenodo.3742113.svg)
- **UNGA** Verbatim Records of the United Nations General Assembly ![](https://zenodo.org/badge/DOI/10.5281/zenodo.3748858.svg)
- **ParisParl** (French Assemblé Nationale) / **AustroParl** (Austria's Nationalrat) / **TweedeKamer** (Dutch Tweede Kamer Staten-General)
- **MigParl**: Debates on migration and integration in Germany's Regional Parliaments

*cp. ParlaCLARIN-Workshops, work towards a TEI-style standardization*

--

### Other Corpora

- **MigPress**: Corpus of reports on migration and integration in Süddeutsche Zeitung und Frankfurter Allgemeine Zeitung (2000-2019)

--

### Dissemination

- Git repositories for TEI-XML
- Open science repository Zenodo for indexed corpora

---

# polmineR - the People's Corpus Miner 

--

- Prerequisites: 
  - Any kind of computer that still has keys (Windows, Linux, macOS)
  - Installation of R/RStudio

--

- Three lines of code will get you polmineR and GermaParl (or any other corpus)


```r
install.packages("polmineR")
install.packages("GermaParl") # includes small sample dataset
GermaParl::germaparl_download_corpus() # get the full corpus (1 GB)
```

--

- Start your inquiry


```r
library(polmineR)
count("GERMAPARL", query = "Europa")
kwic("GERMAPARL", query = "Europa")
```

- Installation options: Run R, RStudio, OpenCPU on server (remote corpus access)



---

background-image: url(img/Le_Penseur_min.jpg)
background-size: cover
class: nobackground, inverse

# Theory is Code
## The "quanlification" frontier

---

# From text to numbers

## The idea of "distant reading"

- "[…] the trouble with close reading […] is that it necessarily depends on an extremely small canon. […] what we really need is a little pact with the devil: we know how to read texts, so now let‘s learn how not to read them. Distant reading, where distance, let me repeat is, is a condition of knowledge. It allows you to focus on units that are much smaller or much larger than the text: devices, themes, types – or genres and systems. And if, between the very small and the very large, the text itself disappears, well, this is one of the cases where one can justifiably say, Less is more.“ (Moretti [2000] 2013: 49)


## The "text as data" movement:

- scaling party positions (wordscore and wordfish) as a driver
-"[…] while our method is designed to analyse the content of a text, it is not necessary for an analyst using the technique to understand, or even read, the texts to which the technique is applied. " (Laver, Benoit &amp; Garry 2003)


---

# Text + Numbers = Quanlification

## An obsolete methodological divide?

--

.pull-left[

### Quantity

- Text as Data
- Natural Language Processing (NLP)
- Data / Text Mining
- Machine Learning (ML)
- "Validate, validate, validate" (Grimmer et al. 2013)
]

--

.pull-right[
### Quality
- eHumanities / Digital Humanities
- Corpus Linguistics 
- Computational Linguistics
- "blended reading" (Stulpe, Lemke 2015), "scalable reading" (Weitin 2017) &amp; related concepts
]

--

### Quanlification

- Epistemological disputes notwithstanding: The necessity to combine qualitative and quantitative approaches to text is conceptually undisputed.

- Software inhibits combining quantity and quality: Tools are there, but setting up a quanlitative project is expensive: Difficult without a dedicated software engineer


---

# Verbs and nouns for corpus analysis

## polmineR: A basic vocabulary for quanlification

- __Corpora and subcorpora__
  - corpus objects: *corpus()*
  - subsetting corpora: *partition()* / *subset()*

--

- __Quantification__
  - counting: *hits()*, *count()*, *dispersion()* (and *size()*)
  - cooccurrences: *cooccuurrences()*, *Cooccurrences()*
  - feature extraction: *features()*
  - term-document-matrices: *as.sparseMatrix()*, *as.TermDocumentMatrix()*

--

- __Qualitative analysis__
  - Keywords-in-context / concordances: *kwic()*
  - full text (of a subcorpus): *get_token_stream()*, *as.markdown()*, *as.html()*, *read()*

---
background-image: url(img/Nerd.jpg)
background-size: cover
class: nobackground, inverse


# Implementing Quanlification 
## Let's Get Things Done

---

# Reading Anywhere: 'fulltext' htmlwidget

## Problem Statement

- **Read Anything:** Cooccurrences, concordances, subcorpora, topic models - there are many different scenarios when you 
- **Read Anywhere:** Include fulltext output into (html) documents and slides, and in GUIs


## Implementation

- polmineR vocabulary: Implementation of a `read()`-method
- GUI: Package 'fulltext' that renders input data into an "htmlwidget" (a truly flexible device)

## Demonstration

- HTML documents with scrollable fulltext [click here for an example](file:///Users/andreasblaette/Lab/github/fulltext/docs/articles/vignette.html#from-a-subcorpus-to-fulltext)
- Slides with `fulltext` htmlwidget [click here for an example](https://polmine.github.io/gallery/crosstalk_ioslides.html#1)
- polmineR shiny App [click here for an example]()


---

# Highlighting and Tooltipping

## Problem Statement

- **Highlighting with multiple colors:** The statistical analysis of text yields variable dictionaries with word weights - visualising multiple dictionaries at the same time will help to gather the semantic sense of numeric analyses
- **Tooltipping :** Colors alone may be misleading. Show numeric information on demand


## Implementation

- polmineR level: Implementation of methods `highlight()` and `tooltips()`
- GUI: Enrich input data for htmlwidgets and amend CSS

## Demonstration

- Validating sentiment analyses with interactive KWIC tables [example]()
- Evaluate topic models with flexdashboard [example]()
- Understanding the data behind cooccurrence graphs [example](https://polmine.github.io/gcdh_slides/widget_3.html)

---


# Annotation

## Problem Statement

- **Annotation and intersubjectivity**: In the qualitative research tradition, annotations are a means to communicate evaluative decisions to other researchers
- **Annotation and machine learning** Annotations (generating labelled data) are a precondition for machine learning


## Implementation

- polmineR level: Implementation of `edit()`-methods 
- Htmlwidget with annotation functionality (different from `fulltext` htmlwidget, as it returns values)

## Demonstration

- Annotate any class inheriting from the `textstat` class (i.e. tables - kwic, cooccurrences, features)
- Simple text annotation with the `annolite` package
- Annotate cooccurrence graphs [example](https://polmine.github.io/gcdh_slides/widget_3.html)

---

# Annotation

- Code Example: Annotate a cooccurrences object


```r
library(polmineR)
s &lt;- cooccurrences("UNGA", "sustainability") # could also be kwic etc.
annotations(s) &lt;- list(name = "annotation", what = "")
edit(s)
```

- Code Example: Annotate fulltext


```r
library(polmineR)
library(annolite) # at github.com/PolMine/annolite, dev-branch

data &lt;- corpus("GERMAPARLMINI") %&gt;%
  subset(speaker == "Volker Kauder") %&gt;% 
  subset(date == "2009-11-10") %&gt;%
  as("partition") %&gt;%
  as.fulltextdata(headline = "Volker Kauder (CDU)")
anno &lt;- annotate(data)
```

---

# The Making of a Quanlification Toolset

## Conscious Uncoupling and Modularization

- [*fulltext*](https://github.com/PolMine/fulltext):&lt;br/&gt;Toolset to generate fulltext display from corpus data

- [*gradget*](https://github.com/PolMine/gradget):&lt;br/&gt;Graph annotation widget

- [*annolite*](https://github.com/PolMine/annolite):&lt;br/&gt;Leightweight Fulltext Display and Annotation Tools

- [*topicanalysis*](https://github.com/PolMine/topicanalysis):&lt;br/&gt;Auxiliary functions for topicmodelling.

- [*quanlify*](https://github.com/PolMine/quanlify):&lt;br&gt;Toolset for the qualitative validation of quantitative text analysis

**Beware! All of this is experimental!**


---

# Discussion. Frontier.

## Vision

- Offer a very flexible set of tools to implement all kinds of workflows that entail distant and close reading with minimal cost
- A **l**eightweight **i**nfrastructure for the **qu**anlitat**i**ve analysis of text **d**ata ("liquid")

--

## Inspiration from the Unix philosophy

- keep it simple, stupid (KISS)
- parsimony (leave as much as possible to existing libraries)
- modularity (identify independent building blocks and develop them soundly)

--

## Discussion Points

- Alternative approaches, relevant previous work
- How much GUI is needed?
- Toolset of framework?
- Towards a people's framework for quanlification?
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
